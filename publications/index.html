<!DOCTYPE html> <html lang="zh-cn"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 成果 | 刘泽超（Liu Zechao） </title> <meta name="author" content="Zechao Liu"> <meta name="description" content="论文及专利"> <meta name="keywords" content="刘泽超, Zechao Liu"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://silenceeagle.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> 刘泽超（Liu Zechao） </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">自我介绍 </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">成果 <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">代码仓库 </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">简历 </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">成果</h1> <p class="post-description">论文及专利</p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#335EFF"> <div>Paper</div> </abbr> </div> <div id="pofnet_cleo" class="col-sm-8"> <div class="title">POFNet: Enlarging the Dynamic Range of Phase Demodulation by Signal Fusion</div> <div class="author"> <em>Zechao Liu</em>, Hongkun Zheng, Chen Zhu, and Lingmei Ma<sup>*</sup> </div> <div class="periodical"> <em>In 2024 Conference on Lasers and Electro-Optics (CLEO)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>To break the π-phase criterion in phase demodulation, POFNet is proposed to fuse the OPD and the phase signal to estimate the unwrapping errors and recover larger phase. The results showcase its superiority performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pofnet_cleo</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Zechao and Zheng, Hongkun and Zhu, Chen and Ma, Lingmei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 Conference on Lasers and Electro-Optics (CLEO)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{POFNet: Enlarging the Dynamic Range of Phase Demodulation by Signal Fusion}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-2}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#335EFF"> <div>Paper</div> </abbr> </div> <div id="zhkjlt" class="col-sm-8"> <div class="title">Detection of Large Dynamic Range Acoustic Signal Using OPD-based Fiber-Optic Interferometric Demodulation with SNR Enhancement</div> <div class="author"> Hongkun Zheng, Lingmei Ma<sup>*</sup> , <em>Zechao Liu</em>, Caiyun Li, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Ruimin Jie, Yiyang Zhuang, Chen Zhu, Yunjiang Rao' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>Journal of Lightwave Technology</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The measurement of acoustic signals at high frequencies with a large dynamic range remains a challenge for phase-demodulation-based fiber acoustic sensing systems due to the phase wrapping phenomenon. Here, an optical path difference (OPD)-assisted demodulation method aiming at breaking the limitations of phase demodulation is reported. By interrogating an imbalanced Michelson interferometer (IMI) with a frequency-modulated pulse light, a time-resolved interference spectrum is obtained and used for OPD demodulation. Theoretical analysis reveals that the variation amplitude of demodulated OPD signal not only is linearly dependent on the amplitude of the acoustic signal applied to the IMI, but also experiences a gain that is directly proportional to the signal frequency. Consequently, compensation of this gain introduces a noise suppression that favors high-frequency signals, resulting in a higher signal-to-noise ratio (SNR) at high frequencies. The method’s capability for detecting both single-frequency and multi-frequency acoustic signals is demonstrated by simulations and experiments, and the results show that the upper-frequency limit of the proposed scheme is at least 40 times the limit of the phase demodulation method for an acoustic signal with an amplitude of 1.135 μϵ. The proposed method can be easily extended to distributed acoustic sensing systems and is of great potential to break the limitation of a restricted dynamic range encountered in traditional phase demodulation methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhkjlt</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zheng, Hongkun and Ma, Lingmei and Liu, Zechao and Li, Caiyun and Jie, Ruimin and Zhuang, Yiyang and Zhu, Chen and Rao, Yunjiang}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Lightwave Technology}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Detection of Large Dynamic Range Acoustic Signal Using OPD-based Fiber-Optic Interferometric Demodulation with SNR Enhancement}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-9}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Acoustics;Demodulation;Optical fiber sensors;Interference;Dynamic range;Interferometers;Frequency modulation;acoustic measurement;interferometer;demodulation;optical fiber sensor;optical path difference}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/JLT.2024.3371702}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#335EFF"> <div>Paper</div> </abbr> </div> <div id="hypersc" class="col-sm-8"> <div class="title">Deep Hyperspherical Clustering for Skin Lesion Medical Image Segmentation</div> <div class="author"> Zuowei Zhang, Songtao Ye , <em>Zechao Liu</em>, Hao Wang<sup>*</sup>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Weiping Ding&lt;sup&gt;*&lt;/sup&gt;' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>IEEE Journal of Biomedical and Health Informatics</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Diagnosis of skin lesions based on imaging techniques remains a challenging task because data (knowledge) uncertainty may reduce accuracy and lead to imprecise results. This paper investigates a new deep hyperspherical clustering (DHC) method for skin lesion medical image segmentation by combining deep convolutional neural networks and the theory of belief functions (TBF). The proposed DHC aims to eliminate the dependence on labeled data, improve segmentation performance, and characterize the imprecision caused by data (knowledge) uncertainty. First, the SLIC superpixel algorithm is employed to group the image into multiple meaningful superpixels, aiming to maximize the use of context without destroying the boundary information. Second, an autoencoder network is designed to transform the superpixels’ information into potential features. Third, a hypersphere loss is developed to train the autoencoder network. The loss is defined to map the input to a pair of hyperspheres so that the network can perceive tiny differences. Finally, the result is redistributed to characterize the imprecision caused by data (knowledge) uncertainty based on the TBF. The proposed DHC method can well characterize the imprecision between skin lesions and non-lesions, which is particularly important for the medical procedures. A series of experiments on four dermoscopic benchmark datasets demonstrate that the proposed DHC yields better segmentation performance, increasing the accuracy of the predictions while can perceive imprecise regions compared to other typical methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hypersc</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zuowei and Ye, Songtao and Liu, Zechao and Wang, Hao and Ding, Weiping}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Journal of Biomedical and Health Informatics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep Hyperspherical Clustering for Skin Lesion Medical Image Segmentation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{27}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3770-3781}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Skin;Lesions;Image segmentation;Feature extraction;Biomedical imaging;Medical diagnostic imaging;Optimization;Melanoma;clustering;imprecision;skin lesion;deep learning;belief functions;image segmentation}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/JBHI.2023.3240297}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#335EFF"> <div>Paper</div> </abbr> </div> <div id="aunwrap" class="col-sm-8"> <div class="title">Phase correction based SNR enhancement for distributed acoustic sensing with strong environmental background interference</div> <div class="author"> Caiyun Li , <em>Zechao Liu</em>, Yiyang Zhuang, Hongkun Zheng, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Chen Zhu, Weiwang Hu, Jianguo Wang, Lingmei Ma&lt;sup&gt;*&lt;/sup&gt;, Yun-Jiang Rao&lt;sup&gt;*&lt;/sup&gt;' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Optics and Lasers in Engineering</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Fiber-optic distributed acoustic sensing (DAS) systems based on phase-sensitive optical time domain reflectometry (Φ-OTDR) measure acoustic waves by demodulating the phase variations of the Rayleigh backscattering (RBS) signals in a sensing optical fiber. However, in harsh environments, strong environmental background interference, coupled with the interference fading of the RBS, would introduce severe distortions in DAS signal that cannot be corrected or even can be worsened by phase unwrapping, thus resulting in low signal to noise ratio (SNR) and even undetectable signal. In this work, a novel method based on trend prediction is proposed to correct the distortions induced by phase unwrapping error around the fading points. The method is further validated in processing the data acquired from a field test performed in ocean environments using a home-built DAS system. By locating and erasing the distortion points, and then detrending, the acoustic signal buried in strong environmental background interference is retrieved with an SNR improvement greater than 10 dB. The results show that the proposed phase correction method can effectively enhance DAS’s SNR for those challenging applications with strong background interference.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">aunwrap</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Phase correction based SNR enhancement for distributed acoustic sensing with strong environmental background interference}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Optics and Lasers in Engineering}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{168}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{107678}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0143-8166}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.optlaseng.2023.107678}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0143816623002075}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Caiyun and Liu, Zechao and Zhuang, Yiyang and Zheng, Hongkun and Zhu, Chen and Hu, Weiwang and Wang, Jianguo and Ma, Lingmei and Rao, Yun-Jiang}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Fiber-optic distributed acoustic sensing systems (DAS), Phase-sensitive optical time domain reflectometry (φ-OTDR), Unwrapped phase, Interference fading, Large dynamic range, Phase distrotion}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#335EFF"> <div>Paper</div> </abbr> </div> <div id="ZHANG2023202" class="col-sm-8"> <div class="title">Mining and reasoning of data uncertainty-induced imprecision in deep image classification</div> <div class="author"> Zuowei Zhang, Liangbo Ning , <em>Zechao Liu</em>, Qingyu Yang, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Weiping Ding&lt;sup&gt;*&lt;/sup&gt;' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Information Fusion</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Existing deep image classification techniques strive to suppress data uncertainty for various reasons such as blur, occlusion, noise, and label error and advance to higher accuracy. However, they ignore data uncertainty-induced imprecision and thus do not work as intended. In this paper, we propose a deep open-source framework to mine and reason the imprecision of such training and test sets, which can present better performance and reduce the risk of misclassification. First, we design a label reassignment mechanism. It allows the network to reassign training labels and allow imperfect training samples with multiple labels. As a result, they are removed from the original classes and considered new imprecise samples to represent partial ignorance. Second, we propose a new imbalanced data enhancement architecture to learn a generalized representation of each (precise and imprecise) class. It helps the network fuse the auxiliary information from both precise and imprecise classes, which is beneficial to extract more distinctive class features from single-labeled samples and characterize uncertainty-induced imprecision in the test set by imprecise test samples. Afterward, methodological analyses and empirical evaluations are conducted. The proposed framework is demonstrated to present better performance on different typical networks (Resnet50, MobileNetV2, DenseNet121, EfficientNetB0, ShuffleNetV2, SENet, SqueezeNet, Xception) based on five publicly available datasets (Imagewoof-5, Flowers, Monkey, Butterfly, and Cifar-10). In addition, several targeted deep techniques for uncertain images or imprecise results are also employed as comparisons to prove the superiority of the proposed framework.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ZHANG2023202</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mining and reasoning of data uncertainty-induced imprecision in deep image classification}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Information Fusion}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{96}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{202-213}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1566-2535}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.inffus.2023.03.014}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1566253523001033}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zuowei and Ning, Liangbo and Liu, Zechao and Yang, Qingyu and Ding, Weiping}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Imprecision, Data uncertainty, Image classification, Deep techniques, Multiple labels}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#335EFF"> <div>Paper</div> </abbr> </div> <div id="unwrapofs" class="col-sm-8"> <div class="title">SNR Improvement for Distributed Acoustic Sensing with Strong Environmental Background Interference</div> <div class="author"> Caiyun Li , <em>Zechao Liu</em>, Hongkun Zheng, Yiyang Zhuang, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Chen Zhu, Weiwang Hu, Jianguo Wang, Lingmei Ma&lt;sup&gt;*&lt;/sup&gt;, Yun-Jiang Rao&lt;sup&gt;*&lt;/sup&gt;' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In 28th International Conference on Optical Fiber Sensors</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>A novel method is proposed to correct the distortions induced by phase unwrapping error. The method is further validated in processing the data acquired from a field test performed in ocean environments using a DAS system.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">unwrapofs</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Caiyun and Liu, Zechao and Zheng, Hongkun and Zhuang, Yiyang and Zhu, Chen and Hu, Weiwang and Wang, Jianguo and Ma, Lingmei and Rao, Yun-Jiang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{28th International Conference on Optical Fiber Sensors}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{28th International Conference on Optical Fiber Sensors}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Distortion; Erbium fibers; Fiber Bragg gratings; Optical time domain reflectometry; Phase unwrapping; Spatial resolution}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{W4.71}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Optica Publishing Group}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SNR Improvement for Distributed Acoustic Sensing with Strong Environmental Background Interference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://opg.optica.org/abstract.cfm?URI=OFS-2023-W4.71}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1364/OFS.2023.W4.71}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FF5733"> <div>Patent</div> </abbr> </div> <div id="CN116956226B" class="col-sm-8"> <div class="title">基于自监督式信号融合的DAS动态范围提升方法和设备</div> <div class="author"> <em> 刘泽超</em>,  马玲梅,  李彩云,  朱琛, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? ' 郑洪坤, 彭威, 田帅飞' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>本发明涉及一种基于自监督式信号融合的DAS动态范围提升方法和设备,方法包括：并行获取双路光纤传感数据,即动态范围未受限制但信噪比较低的DAS信号和因动态范围受限而存在相位解卷绕错误的DAS相位信号,输入自设计的自监督式信号融合模型中,求取相位卷绕系数,并取整,根据取整后的相位卷绕系数和第二光纤传感信号,构建解卷绕后的相位估计值并输出。与现有技术相比,本发明可实时有效修正DAS相位信号因动态范围受限而导致的相位解卷绕错误,恢复真实相位,提升动态范围,且不以牺牲信噪比为代价。</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">CN116956226B</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{刘泽超 and 马玲梅 and 李彩云 and 朱琛 and 郑洪坤 and 彭威 and 田帅飞}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{基于自监督式信号融合的DAS动态范围提升方法和设备}</span><span class="p">,</span>
  <span class="na">edition</span> <span class="p">=</span> <span class="s">{CN116956226B}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{311121 浙江省杭州市余杭区中泰街道科创大道之江实验室}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FF5733"> <div>Patent</div> </abbr> </div> <div id="CN116541744A" class="col-sm-8"> <div class="title">一种光纤传感行人识别方法、装置和存储介质</div> <div class="author"> 彭威 , <em> 刘泽超</em>,  马玲梅,  王皓, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' 程徐' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>本发明涉及一种光纤传感行人识别方法、装置和存储介质,方法包括以下步骤：S1、获取行人经过时的传感数据,对传感数据进行解调,得到相位数据；S2、对相位数据进行切面降采样；S3、对切面降采样后的数据通过矩形滑窗进行切割,得到时间序列信号；S4、将时间序列信号进行尺度划分,得到第一高尺度数据、第一中尺度数据和第一低尺度数据；S5、将划分得到的数据输入训练好的阶梯形的稠密卷积网络结构中,得到分类识别结果。与现有技术相比,本发明基于多尺度和注意力机制,实现高精度的行人动作识别。</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">CN116541744A</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{彭威 and 刘泽超 and 马玲梅 and 王皓 and 程徐}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{一种光纤传感行人识别方法、装置和存储介质}</span><span class="p">,</span>
  <span class="na">edition</span> <span class="p">=</span> <span class="s">{CN116541744A}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{311121 浙江省杭州市余杭区中泰街道之江实验室南湖总部}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FF5733"> <div>Patent</div> </abbr> </div> <div id="CN115855123B" class="col-sm-8"> <div class="title">基于畸变点检测的光纤传感信号相位错误修正方法和装置</div> <div class="author"> <em> 刘泽超</em>,  李彩云,  马玲梅,  胡威旺, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? ' 彭威, 王皓' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>本发明涉及一种基于畸变点检测的光纤传感信号相位错误修正方法和装置,方法包括以下步骤：获取光纤传感数据,进行解调,得到相位数据,该相位数据包括光纤上多个位置处的相位变化信号；对相位数据中的各个位置信号分别进行相位解卷绕,然后进行重采样,获取各个位置的相位解卷绕数据；根据相位解卷绕数据的信号变化量,确定畸变点；根据畸变点的分布确定畸变点的类型,可分为尖峰畸变点、连续台阶畸变点和单次畸变点,从而进行对应的修正处理,然后再经去趋势操作,输出修正后的相位信号。与现有技术相比,本发明可实时有效修正复杂情况下的相位错误,抑制衰落噪声,提升信噪比。</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">CN115855123B</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{刘泽超 and 李彩云 and 马玲梅 and 胡威旺 and 彭威 and 王皓}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{基于畸变点检测的光纤传感信号相位错误修正方法和装置}</span><span class="p">,</span>
  <span class="na">edition</span> <span class="p">=</span> <span class="s">{CN115855123B}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{27}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{311121 浙江省杭州市余杭区中泰街道之江实验室南湖总部}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FF5733"> <div>Patent</div> </abbr> </div> <div id="CN111291639B" class="col-sm-8"> <div class="title">基于分层变分自编码的跨源舰船特征融合学习与识别方法</div> <div class="author"> 文载道 , <em> 刘泽超</em>,  刘准钆, and  潘泉 </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>本发明公开了一种基于分层变分自编码的跨源舰船特征融合学习与识别方法,获取目标舰船的光学或合成孔径雷达待识别图像；使用训练好的分层式变分自编码网络中的第一编码器提取待识别图像中的舰船类别间差异性特征及数据源间差异性特征；使用训练好的分层式变分自编码网络中的第二编码器对舰船类别间差异性特征及数据源间差异性特征进行分析,确定待识别图像中的目标舰船的类别及待识别图像的数据源类别；本发明利用分层式变分自编码网络,从大量的无法配准的异源舰船目标图像中自动提取表示性/解释性与判别性兼具的结构化特征,实现跨源舰船特征融合学习,以及舰船目标的精准识别。</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">CN111291639B</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{文载道 and 刘泽超 and 刘准钆 and 潘泉}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{基于分层变分自编码的跨源舰船特征融合学习与识别方法}</span><span class="p">,</span>
  <span class="na">edition</span> <span class="p">=</span> <span class="s">{CN111291639B}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{710072 陕西省西安市友谊西路127号}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FF5733"> <div>Patent</div> </abbr> </div> <div id="CN114818839B" class="col-sm-8"> <div class="title">一种基于深度学习的光纤传感水声信号识别方法及装置</div> <div class="author"> 高嘉豪,  彭威 , <em> 刘泽超</em>,  王皓, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? ' 马玲梅, 饶云江, 叶松涛' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>本发明提供一种基于深度学习的光纤传感水声信号识别方法,该方法降低了光纤传感水声信号识别的难度,通过最优聚类模型,将无监督学习方式转化为有监督学习的方式,使识别未知的目标事件信号成为可能；以光纤传感系统自身固有噪声信号分解分量作为训练数据,构建开集识别网络,可用于识别任意不属于系统噪声的目标事件信号,有效提高了模型的泛化能力。</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">CN114818839B</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{高嘉豪 and 彭威 and 刘泽超 and 王皓 and 马玲梅 and 饶云江 and 叶松涛}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{一种基于深度学习的光纤传感水声信号识别方法及装置}</span><span class="p">,</span>
  <span class="na">edition</span> <span class="p">=</span> <span class="s">{CN114818839B}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{311121 浙江省杭州市余杭区之江实验室南湖总部}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FF5733"> <div>Patent</div> </abbr> </div> <div id="CN114754857B" class="col-sm-8"> <div class="title">一种两段式光纤传感水声信号补偿方法和装置</div> <div class="author"> 彭威 , <em> 刘泽超</em>,  王皓,  马玲梅, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' 饶云江' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>本发明公开了一种两段式光纤传感水声信号补偿方法和装置。该水声信号补偿方法在传感信号频域分解处理的过程中,首先通过遗传算法寻找传感信号变分模态分解的最优惩罚因子和迭代阈值参数,使得信号处理过程中尽可能降低信号损失；其次,将损失信号通过基于多尺度排列熵的补偿算法,回补至各模态分量,使得水声传感信号在频域分解处理的过程中尽可能少的损失有用信息,提升传感信号的信噪比。</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">CN114754857B</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{彭威 and 刘泽超 and 王皓 and 马玲梅 and 饶云江}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{一种两段式光纤传感水声信号补偿方法和装置}</span><span class="p">,</span>
  <span class="na">edition</span> <span class="p">=</span> <span class="s">{CN114754857B}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{310023 浙江省杭州市余杭区之江实验室南湖总部}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FF5733"> <div>Patent</div> </abbr> </div> <div id="CN114077854B" class="col-sm-8"> <div class="title">一种基于自适应VMD的φ-OTDR水声信号处理方法和装置</div> <div class="author"> 彭威 , <em> 刘泽超</em>,  王皓,  马玲梅, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? ' 饶云江, 叶松涛' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>本发明公开了一种基于自适应VMD的φ-OTDR水声信号处理方法和装置。该水声信号处理方法将信号从时域转换至频域进行分析,对光纤传感器中不同位置的传感信号进行变分模态分解处理,基于信号噪声的特性,提取全变分、分形维数、排列熵、能量特征用于噪声信号的特征离散化。同时,我们根据最大化簇间间距和最小化簇内间距原则设计了一种信号可分离性指标,来观测和优化变分模态分解过程,使得传感信号分解得到的模态分量可以更清晰的划分噪声和目标信号。</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">CN114077854B</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{彭威 and 刘泽超 and 王皓 and 马玲梅 and 饶云江 and 叶松涛}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{一种基于自适应VMD的φ-OTDR水声信号处理方法和装置}</span><span class="p">,</span>
  <span class="na">edition</span> <span class="p">=</span> <span class="s">{CN114077854B}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{310023 浙江省杭州市余杭区之江实验室南湖总部}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FF5733"> <div>Patent</div> </abbr> </div> <div id="CN113654642B" class="col-sm-8"> <div class="title">一种基于参考传感器的分布式声波传感降噪系统及方法</div> <div class="author"> 马玲梅,  应马可,  胡威旺 , <em> 刘泽超</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? ' 王皓, 饶云江' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>本发明公开了一种基于参考传感器的分布式声波传感降噪系统及方法,该系统包括相位型光时域反射模块,参考传感器,噪声补偿算法模块；该方法包括：S1:建立相位型光时域反射模块；S2:设立参考传感器用以获得所述相位型光时域反射模块的噪声特征；S3:通过噪声补偿算法模块对所述噪声特征计算补偿。本发明通过参考传感器收集本地信号,通过参考端收集的信号训练深度神经网络,对噪声进行预测,由此实现噪声补偿的功能,本发明提出多种参考传感器的架构,其实现方法简便,手段灵活,可在不同使用环境中实现高可靠,低延迟的实时降噪补偿功能。</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">CN113654642B</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{马玲梅 and 应马可 and 胡威旺 and 刘泽超 and 王皓 and 饶云江}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{一种基于参考传感器的分布式声波传感降噪系统及方法}</span><span class="p">,</span>
  <span class="na">edition</span> <span class="p">=</span> <span class="s">{CN113654642B}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{310023 浙江省杭州市余杭区文一西路1818号}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#335EFF"> <div>Paper</div> </abbr> </div> <div id="bf-knn" class="col-sm-8"> <div class="title">A new incomplete pattern belief classification method with multiple estimations based on KNN</div> <div class="author"> Zong-fang Ma, Hong-peng Tian , <em>Ze-chao Liu</em>, and Zuo-wei Zhang<sup>*</sup> </div> <div class="periodical"> <em>Applied Soft Computing</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The classification of missing data is a challenging task, because the lack of pattern attributes may bring uncertainty to the classification results and most classification methods produce only one estimation, which may have a risk of misclassification. A new incomplete pattern belief classification (PBC) method with multiple estimations based on K-nearest neighbors (KNNs) is proposed to deal with missing data. PBC preliminarily classifies the incomplete pattern using its KNNs obtained by the known attributes. The pattern whose KNNs contain only one class information can be directly divided into this class. If not, the p (p≤c) estimations will be computed according to the different KNNs in different classes when p classes are included in the KNNs of the pattern and it will yield p pieces of classification results by the chosen classifier. Then, a weighted possibility distance method is used to further divide the p classification results with their KNNs’ classification information. The pattern with similar possibility distances in different classes will be reasonably classified into a proper meta-class under the framework of belief functions theory, which truly reflects the uncertainty of the pattern caused by missing values and effectively reduces the error rate. Experiments on both artificial and real data sets show that PBC is effective for dealing with missing data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bf-knn</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A new incomplete pattern belief classification method with multiple estimations based on KNN}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Applied Soft Computing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{90}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{106175}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1568-4946}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.asoc.2020.106175}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1568494620301150}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ma, Zong-fang and Tian, Hong-peng and Liu, Ze-chao and Zhang, Zuo-wei}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Missing data, -nearest neighbors, Possibility distance, Belief functions theory, Uncertainty}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Zechao Liu. 改编自基于 <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> 的 <a href="https://github.com/george-gca/multi-language-al-folio" rel="external nofollow noopener" target="_blank">multi-language-al-folio</a>主题. 部署于<a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-BQTH8NNDNY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-BQTH8NNDNY");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="输入以开始搜索"> <div class="modal-footer" slot="footer"> <span class="help"> <svg version="1.0" class="ninja-examplekey" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 1280 1280"> <path d="M1013 376c0 73.4-.4 113.3-1.1 120.2a159.9 159.9 0 0 1-90.2 127.3c-20 9.6-36.7 14-59.2 15.5-7.1.5-121.9.9-255 1h-242l95.5-95.5 95.5-95.5-38.3-38.2-38.2-38.3-160 160c-88 88-160 160.4-160 161 0 .6 72 73 160 161l160 160 38.2-38.3 38.3-38.2-95.5-95.5-95.5-95.5h251.1c252.9 0 259.8-.1 281.4-3.6 72.1-11.8 136.9-54.1 178.5-116.4 8.6-12.9 22.6-40.5 28-55.4 4.4-12 10.7-36.1 13.1-50.6 1.6-9.6 1.8-21 2.1-132.8l.4-122.2H1013v110z"></path> </svg> 跳转至选择栏 </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M20 12l-1.41-1.41L13 16.17V4h-2v12.17l-5.58-5.59L4 12l8 8 8-8z"></path> </svg> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M4 12l1.41 1.41L11 7.83V20h2V7.83l5.58 5.59L20 12l-8-8-8 8z"></path> </svg> 跳转至导航栏 </span> <span class="help"> <span class="ninja-examplekey esc">esc</span> 关闭 </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey backspace" viewbox="0 0 20 20" fill="currentColor"> <path fill-rule="evenodd" d="M6.707 4.879A3 3 0 018.828 4H15a3 3 0 013 3v6a3 3 0 01-3 3H8.828a3 3 0 01-2.12-.879l-4.415-4.414a1 1 0 010-1.414l4.414-4.414zm4 2.414a1 1 0 00-1.414 1.414L10.586 10l-1.293 1.293a1 1 0 101.414 1.414L12 11.414l1.293 1.293a1 1 0 001.414-1.414L13.414 10l1.293-1.293a1 1 0 00-1.414-1.414L12 8.586l-1.293-1.293z" clip-rule="evenodd"></path> </svg> 返回上一级 </span> </div> </ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-\u81ea\u6211\u4ecb\u7ecd",title:"\u81ea\u6211\u4ecb\u7ecd",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/"}},{id:"nav-\u6210\u679c",title:"\u6210\u679c",description:"\u8bba\u6587\u53ca\u4e13\u5229",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/publications/"}},{id:"nav-\u4ee3\u7801\u4ed3\u5e93",title:"\u4ee3\u7801\u4ed3\u5e93",description:"\u6211\u7684\u90e8\u5206\u4ee3\u7801\u4ed3\u5e93\u3002",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/repositories/"}},{id:"nav-\u7b80\u5386",title:"\u7b80\u5386",description:"\u4e2a\u4eba\u7b80\u5386",section:"\u5bfc\u822a\u83dc\u5355",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"\u5e16\u5b50",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"\u5e16\u5b50",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"\u5e16\u5b50",handler:()=>{window.location.href="/assets/pdf/pt-br/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2018/distill/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-uma-postagem-com-c\xf3digo",title:"uma postagem com c\xf3digo",description:"um exemplo de uma postagem em um blog com c\xf3digo",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"\u5e16\u5b50",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-um-an\xfancio-simples-em-uma-linha-com-markdown-emoji-sparkles-smile",title:'Um an\xfancio simples em uma linha com Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"\u65b0\u95fb"},{id:"news-um-an\xfancio-longo-com-detalhes",title:"Um an\xfancio longo com detalhes",description:"",section:"\u65b0\u95fb",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-test-1",title:"test 1",description:"",section:"\u65b0\u95fb"},{id:"projects-project-7",title:"project 7",description:"with background image",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/9_project/"}},{id:"projects-projeto-1",title:"projeto 1",description:"com imagem de fundo",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-projeto-2",title:"projeto 2",description:"um projeto com imagem de fundo e coment\xe1rios do giscus",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-projeto-3-com-um-nome-bem-longo",title:"projeto 3 com um nome bem longo",description:"um projeto que redireciona pra outro website",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-projeto-4",title:"projeto 4",description:"outro sem imagem",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-projeto-5",title:"projeto 5",description:"um projeto com imagem de fundo",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-projeto-6",title:"projeto 6",description:"um projeto sem imagem",section:"\u9879\u76ee",handler:()=>{window.location.href="/projects/6_project/"}},{id:"socials-email",title:"\u53d1\u9001\u90ae\u4ef6",section:"\u793e\u4ea4\u8d26\u53f7",handler:()=>{window.open("mailto:%63%7A%6C%69%75%7A%65%63%68%61%6F@%6F%75%74%6C%6F%6F%6B.%63%6F%6D","_blank")}},{id:"socials-orcid",title:"ORCID",section:"\u793e\u4ea4\u8d26\u53f7",handler:()=>{window.open("https://orcid.org/0000-0002-9350-5168","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"\u793e\u4ea4\u8d26\u53f7",handler:()=>{window.open("https://scholar.google.com/citations?user=g5UuAGIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"\u793e\u4ea4\u8d26\u53f7",handler:()=>{window.open("https://github.com/SilenceEagle","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"\u793e\u4ea4\u8d26\u53f7",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"\u6d45\u8272\u4e3b\u9898",description:"\u5c06\u7f51\u7ad9\u4e3b\u9898\u66f4\u6539\u4e3a\u6d45\u8272",section:"\u4e3b\u9898",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"\u6df1\u8272\u4e3b\u9898",description:"\u5c06\u7f51\u7ad9\u4e3b\u9898\u66f4\u6539\u4e3a\u6df1\u8272",section:"\u4e3b\u9898",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"\u7cfb\u7edf\u9ed8\u8ba4",description:"\u5c06\u7f51\u7ad9\u4e3b\u9898\u66f4\u6539\u4e3a\u7cfb\u7edf\u9ed8\u8ba4",section:"\u4e3b\u9898",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>